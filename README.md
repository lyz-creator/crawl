# Crawl - 学术论文爬虫工具

![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

Crawl 是一个用于爬取学术会议论文的Python工具集，包含静态网页和动态网页两种爬取方案。

## 功能特性

- 🌐 双模式支持：提供静态网页和动态网页两种爬取方案
- 📑 PDF下载：自动识别并下载论文PDF文件
- 🛡️ 反爬处理：内置随机延迟和请求头管理
- 📂 文件管理：自动清理文件名并分类保存
- 🚦 自动化流程：一键式运行，自动处理异常
